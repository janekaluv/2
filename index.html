<!DOCTYPE html>
<html>
<head>
    <title>Reliable Background Remover</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; }
        #upload-container { margin: 20px 0; padding: 30px; border: 2px dashed #ccc; text-align: center; background: #f9f9f9; }
        #original, #result { max-width: 90%; max-height: 500px; display: none; border: 1px solid #eee; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        #download { margin: 20px auto; padding: 12px 24px; background: #4CAF50; color: white; border-radius: 4px; display: none; font-weight: bold; }
        #status { margin: 15px 0; min-height: 24px; font-size: 16px; }
        .container { display: flex; gap: 30px; justify-content: center; margin-top: 20px; }
        .column { flex: 1; text-align: center; }
        button { padding: 12px 24px; background: #4285f4; color: white; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; }
        #progress { width: 100%; margin: 10px 0; display: none; }
    </style>
</head>
<body>
    <h1>Professional Background Remover</h1>
    <div id="upload-container">
        <input type="file" id="upload" accept="image/*" style="display: none;">
        <button onclick="document.getElementById('upload').click()">Select Image</button>
        <p>or drag and drop image here</p>
    </div>
    
    <div id="status">Loading model (this may take a minute)...</div>
    <progress id="progress" value="0" max="100"></progress>
    
    <div class="container">
        <div class="column">
            <h3>Original</h3>
            <img id="original">
        </div>
        <div class="column">
            <h3>Result</h3>
            <canvas id="result"></canvas>
        </div>
    </div>
    
    <a id="download" href="#" download="perfect-bg-removed.png">Download Result</a>

    <script>
        // Configuration
        const MODEL_PATH = 'model/model.json';
        const TARGET_SIZE = 320; // UÂ²-Net processing size
        let model = null;
        let isProcessing = false;
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            setupDragDrop();
            loadModel();
            
            document.getElementById('upload').addEventListener('change', (e) => {
                if (!isProcessing && e.target.files[0]) processFile(e.target.files[0]);
            });
        });
        
        // Setup drag and drop
        function setupDragDrop() {
            const container = document.getElementById('upload-container');
            
            container.addEventListener('dragover', (e) => {
                e.preventDefault();
                container.style.borderColor = '#4285f4';
                container.style.background = '#f0f7ff';
            });
            
            container.addEventListener('dragleave', () => {
                container.style.borderColor = '#ccc';
                container.style.background = '#f9f9f9';
            });
            
            container.addEventListener('drop', (e) => {
                e.preventDefault();
                container.style.borderColor = '#ccc';
                container.style.background = '#f9f9f9';
                if (!isProcessing && e.dataTransfer.files[0]) processFile(e.dataTransfer.files[0]);
            });
        }
        
        // Load TensorFlow.js model with WebGL fixes
        async function loadModel() {
            try {
                document.getElementById('status').textContent = "Loading AI model...";
                document.getElementById('progress').style.display = 'block';
                
                // First verify model exists
                const response = await fetch(MODEL_PATH);
                if (!response.ok) throw new Error("Model files not found");
                
                // Important WebGL fixes
                const glContext = tf.backend().getGPGPUContext().gl;
                glContext.getExtension('WEBGL_lose_context').loseContext();
                
                // Load the model with progress tracking
                model = await tf.loadGraphModel(MODEL_PATH, {
                    onProgress: (progress) => {
                        const percent = Math.round(progress * 100);
                        document.getElementById('progress').value = percent;
                        document.getElementById('status').textContent = `Loading model: ${percent}%`;
                    }
                });
                
                document.getElementById('progress').style.display = 'none';
                document.getElementById('status').textContent = "Ready! Select an image";
            } catch (error) {
                document.getElementById('status').textContent = `Error loading model: ${error.message}`;
                console.error("Model loading failed:", error);
            }
        }
        
        // Process uploaded file with WebGL safety
        function processFile(file) {
            if (!file.type.match('image.*')) {
                document.getElementById('status').textContent = "Please select an image file";
                return;
            }
            
            isProcessing = true;
            const img = new Image();
            img.onload = async () => {
                if (model) {
                    try {
                        document.getElementById('status').textContent = "Processing...";
                        
                        // Show original image
                        document.getElementById('original').src = img.src;
                        document.getElementById('original').style.display = 'block';
                        
                        // Create processing canvas
                        const { canvas, offsetX, offsetY, width, height } = createPaddedCanvas(img);
                        
                        // Process with model (with WebGL safety)
                        const maskData = await safelyProcessWithModel(canvas);
                        
                        if (maskData) {
                            // Create final result
                            await createFinalResult(img, maskData, offsetX, offsetY, width, height);
                            document.getElementById('status').textContent = "Done!";
                        }
                    } catch (error) {
                        document.getElementById('status').textContent = `Error: ${error.message}`;
                        console.error("Processing error:", error);
                    } finally {
                        isProcessing = false;
                        // Force garbage collection
                        await tf.nextFrame();
                    }
                } else {
                    document.getElementById('status').textContent = "Model not loaded yet";
                    isProcessing = false;
                }
            };
            img.src = URL.createObjectURL(file);
        }
        
        // Safe model processing with WebGL error handling
        async function safelyProcessWithModel(canvas) {
            try {
                // Create input tensor
                const tensor = tf.tidy(() => {
                    return tf.browser.fromPixels(canvas)
                        .toFloat()
                        .div(255)
                        .expandDims();
                });
                
                // Execute model with WebGL safety
                const output = await model.executeAsync(tensor);
                
                // Convert output to array
                const maskArray = await processModelOutput(output);
                
                // Clean up
                tensor.dispose();
                if (output !== maskArray) output.dispose();
                
                return maskArray;
            } catch (error) {
                console.error("WebGL processing error:", error);
                // Recover from WebGL errors
                const glContext = tf.backend().getGPGPUContext().gl;
                glContext.getExtension('WEBGL_lose_context').loseContext();
                throw error;
            }
        }
        
        // Create properly padded canvas
        function createPaddedCanvas(img) {
            const canvas = document.createElement('canvas');
            canvas.width = TARGET_SIZE;
            canvas.height = TARGET_SIZE;
            const ctx = canvas.getContext('2d');
            
            // Fill with black background
            ctx.fillStyle = 'black';
            ctx.fillRect(0, 0, TARGET_SIZE, TARGET_SIZE);
            
            // Calculate dimensions to maintain aspect ratio
            const ratio = Math.min(
                TARGET_SIZE / img.width, 
                TARGET_SIZE / img.height
            );
            const width = Math.floor(img.width * ratio);
            const height = Math.floor(img.height * ratio);
            const offsetX = (TARGET_SIZE - width) / 2;
            const offsetY = (TARGET_SIZE - height) / 2;
            
            // Draw centered image
            ctx.drawImage(img, offsetX, offsetY, width, height);
            
            return { canvas, offsetX, offsetY, width, height };
        }
        
        // Process model output
        async function processModelOutput(output) {
            // Get the actual mask tensor
            let maskTensor = output;
            if (Array.isArray(output)) {
                maskTensor = output[0]; // Take first output if multiple
            }
            
            // Remove batch dimension if needed
            if (maskTensor.shape && maskTensor.shape.length === 4) {
                maskTensor = maskTensor.squeeze([0]);
            }
            
            // Convert to array
            const maskArray = await maskTensor.array();
            
            // Clean up
            if (maskTensor !== output) maskTensor.dispose();
            if (Array.isArray(output)) {
                output.forEach(t => t.dispose());
            }
            
            return maskArray;
        }
        
        // Create final high-quality result
        async function createFinalResult(img, maskArray, offsetX, offsetY, width, height) {
            const resultCanvas = document.getElementById('result');
            resultCanvas.width = img.width;
            resultCanvas.height = img.height;
            const resultCtx = resultCanvas.getContext('2d');
            
            // Draw original image
            resultCtx.drawImage(img, 0, 0);
            
            // Get image data
            const imageData = resultCtx.getImageData(0, 0, img.width, img.height);
            
            // Calculate scale factors
            const scaleX = width / TARGET_SIZE;
            const scaleY = height / TARGET_SIZE;
            
            // Edge refinement parameters
            const edgeSmoothingRadius = 2;
            const edgeThreshold = 0.3;
            
            // Apply mask to each pixel with edge refinement
            for (let y = 0; y < img.height; y++) {
                for (let x = 0; x < img.width; x++) {
                    // Calculate position in mask
                    const maskX = Math.min(TARGET_SIZE - 1, Math.floor((x / img.width) * width / scaleX));
                    const maskY = Math.min(TARGET_SIZE - 1, Math.floor((y / img.height) * height / scaleY));
                    
                    // Get base mask value
                    let maskValue = maskArray[maskY][maskX];
                    
                    // Edge refinement - check neighboring pixels
                    if (maskValue > edgeThreshold && maskValue < (1 - edgeThreshold)) {
                        let edgeSum = 0;
                        let edgeCount = 0;
                        
                        for (let dy = -edgeSmoothingRadius; dy <= edgeSmoothingRadius; dy++) {
                            for (let dx = -edgeSmoothingRadius; dx <= edgeSmoothingRadius; dx++) {
                                const nx = Math.min(TARGET_SIZE - 1, Math.max(0, maskX + dx));
                                const ny = Math.min(TARGET_SIZE - 1, Math.max(0, maskY + dy));
                                
                                edgeSum += maskArray[ny][nx];
                                edgeCount++;
                            }
                        }
                        
                        // Smooth transition at edges
                        maskValue = edgeSum / edgeCount;
                    }
                    
                    // Apply threshold after smoothing
                    const alpha = maskValue > 0.5 ? 255 : 0;
                    
                    // Set alpha channel
                    const idx = (y * img.width + x) * 4 + 3;
                    imageData.data[idx] = alpha;
                }
            }
            
            // Apply to result canvas
            resultCtx.putImageData(imageData, 0, 0);
            resultCanvas.style.display = 'block';
            
            // Set download link
            document.getElementById('download').href = resultCanvas.toDataURL('image/png');
            document.getElementById('download').style.display = 'inline-block';
        }
    </script>
</body>
</html>
