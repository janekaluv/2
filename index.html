<!DOCTYPE html>
<html>
<head>
    <title>Optimized Background Remover</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        #upload-container { margin: 20px 0; padding: 20px; border: 2px dashed #ccc; text-align: center; }
        #original, #result { max-width: 100%; max-height: 400px; display: none; margin-top: 20px; border: 1px solid #eee; }
        #download { margin: 20px auto; padding: 10px 20px; background: #4CAF50; color: white; border: none; border-radius: 4px; display: none; }
        #status { margin: 10px 0; min-height: 24px; }
        .container { display: flex; gap: 20px; justify-content: center; }
        .column { flex: 1; text-align: center; }
        button { padding: 10px 20px; background: #4285f4; color: white; border: none; border-radius: 4px; cursor: pointer; }
        #progress { width: 100%; margin: 10px 0; display: none; }
    </style>
</head>
<body>
    <h1>Background Remover</h1>
    <div id="upload-container">
        <input type="file" id="upload" accept="image/*" style="display: none;">
        <button onclick="document.getElementById('upload').click()">Select Image</button>
        <p>or drag and drop image here</p>
    </div>
    
    <div id="status">Loading model...</div>
    <progress id="progress" value="0" max="100"></progress>
    
    <div class="container">
        <div class="column">
            <h3>Original</h3>
            <img id="original">
        </div>
        <div class="column">
            <h3>Result</h3>
            <canvas id="result"></canvas>
        </div>
    </div>
    
    <a id="download" href="#" download="no-bg.png">Download Result</a>

    <script>
        // Configuration
        const MODEL_PATH = 'model/model.json';
        const TARGET_SIZE = 320; // UÂ²-Net expects 320x320
        
        // Global variables
        let model = null;
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            setupDragDrop();
            loadModel();
            
            document.getElementById('upload').addEventListener('change', (e) => {
                if (e.target.files[0]) processFile(e.target.files[0]);
            });
        });
        
        // Setup drag and drop
        function setupDragDrop() {
            const container = document.getElementById('upload-container');
            
            container.addEventListener('dragover', (e) => {
                e.preventDefault();
                container.style.borderColor = '#4285f4';
            });
            
            container.addEventListener('dragleave', () => {
                container.style.borderColor = '#ccc';
            });
            
            container.addEventListener('drop', (e) => {
                e.preventDefault();
                container.style.borderColor = '#ccc';
                if (e.dataTransfer.files[0]) processFile(e.dataTransfer.files[0]);
            });
        }
        
        // Load TensorFlow.js model with memory management
        async function loadModel() {
            try {
                document.getElementById('status').textContent = "Loading model...";
                document.getElementById('progress').style.display = 'block';
                
                // Verify model exists
                const response = await fetch(MODEL_PATH);
                if (!response.ok) throw new Error("Model files not found");
                
                // Load the model with progress updates
                model = await tf.loadGraphModel(MODEL_PATH, {
                    onProgress: (progress) => {
                        const percent = Math.round(progress * 100);
                        document.getElementById('progress').value = percent;
                        document.getElementById('status').textContent = `Loading model: ${percent}%`;
                    }
                });
                
                document.getElementById('progress').style.display = 'none';
                document.getElementById('status').textContent = "Ready! Select an image";
            } catch (error) {
                document.getElementById('status').textContent = `Error loading model: ${error.message}`;
                console.error("Model loading failed:", error);
            }
        }
        
        // Process uploaded file with memory management
        function processFile(file) {
            if (!file.type.match('image.*')) {
                document.getElementById('status').textContent = "Please select an image file";
                return;
            }
            
            const img = new Image();
            img.onload = async () => {
                if (model) {
                    try {
                        document.getElementById('status').textContent = "Processing...";
                        
                        // Show original
                        document.getElementById('original').src = img.src;
                        document.getElementById('original').style.display = 'block';
                        
                        // Create working canvas
                        const { canvas, offsetX, offsetY, width, height } = createPaddedCanvas(img);
                        
                        // Process with model - with memory cleanup
                        const maskData = await tf.tidy(() => {
                            const tensor = tf.browser.fromPixels(canvas)
                                .toFloat()
                                .div(255)
                                .expandDims();
                            
                            // Execute model and get data
                            const output = model.execute(tensor);
                            
                            // Handle different output formats
                            let mask;
                            if (output.shape && output.shape.length === 4) {
                                mask = output.squeeze([0]); // Remove batch dimension
                            } else {
                                mask = output;
                            }
                            
                            // Convert to data before disposing
                            return mask.dataSync();
                        });
                        
                        // Create final result
                        await createFinalResult(img, maskData, offsetX, offsetY, width, height);
                        
                        document.getElementById('status').textContent = "Done!";
                    } catch (error) {
                        document.getElementById('status').textContent = `Error: ${error.message}`;
                        console.error("Processing error:", error);
                        
                        // Force garbage collection
                        await tf.nextFrame();
                    }
                } else {
                    document.getElementById('status').textContent = "Model not loaded yet";
                }
            };
            img.src = URL.createObjectURL(file);
        }
        
        // Create properly padded canvas
        function createPaddedCanvas(img) {
            const canvas = document.createElement('canvas');
            canvas.width = TARGET_SIZE;
            canvas.height = TARGET_SIZE;
            const ctx = canvas.getContext('2d');
            
            // Fill with black background
            ctx.fillStyle = 'black';
            ctx.fillRect(0, 0, TARGET_SIZE, TARGET_SIZE);
            
            // Calculate dimensions to maintain aspect ratio
            const ratio = Math.min(
                TARGET_SIZE / img.width, 
                TARGET_SIZE / img.height
            );
            const width = Math.floor(img.width * ratio);
            const height = Math.floor(img.height * ratio);
            const offsetX = (TARGET_SIZE - width) / 2;
            const offsetY = (TARGET_SIZE - height) / 2;
            
            // Draw centered image
            ctx.drawImage(img, offsetX, offsetY, width, height);
            
            return { canvas, offsetX, offsetY, width, height };
        }
        
        // Create final result using mask data
        async function createFinalResult(img, maskData, offsetX, offsetY, width, height) {
            const resultCanvas = document.getElementById('result');
            resultCanvas.width = img.width;
            resultCanvas.height = img.height;
            const resultCtx = resultCanvas.getContext('2d');
            
            // Draw original image
            resultCtx.drawImage(img, 0, 0);
            
            // Get image data
            const imageData = resultCtx.getImageData(0, 0, img.width, img.height);
            
            // Calculate scale factors
            const scaleX = width / TARGET_SIZE;
            const scaleY = height / TARGET_SIZE;
            
            // Apply mask to each pixel
            for (let y = 0; y < img.height; y++) {
                for (let x = 0; x < img.width; x++) {
                    // Calculate position in mask
                    const maskX = Math.min(TARGET_SIZE - 1, Math.floor((x / img.width) * width / scaleX));
                    const maskY = Math.min(TARGET_SIZE - 1, Math.floor((y / img.height) * height / scaleY));
                    
                    // Get mask value (using dataSync() array)
                    const maskValue = maskData[maskY * TARGET_SIZE + maskX] > 0.5 ? 1 : 0;
                    
                    // Set alpha channel
                    const idx = (y * img.width + x) * 4 + 3;
                    imageData.data[idx] = maskValue * 255;
                }
            }
            
            // Apply to result canvas
            resultCtx.putImageData(imageData, 0, 0);
            resultCanvas.style.display = 'block';
            
            // Set download link
            document.getElementById('download').href = resultCanvas.toDataURL('image/png');
            document.getElementById('download').style.display = 'inline-block';
            
            // Force garbage collection
            await tf.nextFrame();
        }
    </script>
</body>
</html>
