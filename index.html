<!DOCTYPE html>
<html>
<head>
    <title>Background Remover</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        #upload-container { margin: 20px 0; padding: 20px; border: 2px dashed #ccc; text-align: center; }
        #original, #result { max-width: 100%; margin-top: 20px; display: none; }
        #download { margin-top: 10px; display: none; padding: 8px 16px; background: #4CAF50; color: white; text-decoration: none; }
        #status { margin: 10px 0; min-height: 24px; }
        .container { display: flex; gap: 20px; justify-content: center; }
        .column { flex: 1; }
    </style>
</head>
<body>
    <h1>Unlimited Background Remover</h1>
    <div id="upload-container">
        <input type="file" id="upload" accept="image/*" style="display: none;">
        <button onclick="document.getElementById('upload').click()">Select Image</button>
        <p>or drag and drop image here</p>
    </div>
    
    <div id="status">Loading model...</div>
    
    <div class="container">
        <div class="column">
            <h3>Original</h3>
            <img id="original">
        </div>
        <div class="column">
            <h3>Result</h3>
            <canvas id="result"></canvas>
        </div>
    </div>
    
    <a id="download" href="#" download="no-bg.png">Download Result</a>

    <script>
        // Model configuration
        const MODEL_PATH = 'model/model.json';
        const TARGET_SIZE = 320; // U²-Net expects 320x320 input
        
        // Global variables
        let model = null;
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            setupDragDrop();
            loadModel();
            
            document.getElementById('upload').addEventListener('change', (e) => {
                if (e.target.files[0]) processFile(e.target.files[0]);
            });
        });
        
        // Setup drag and drop
        function setupDragDrop() {
            const container = document.getElementById('upload-container');
            
            container.addEventListener('dragover', (e) => {
                e.preventDefault();
                container.style.borderColor = '#4CAF50';
            });
            
            container.addEventListener('dragleave', () => {
                container.style.borderColor = '#ccc';
            });
            
            container.addEventListener('drop', (e) => {
                e.preventDefault();
                container.style.borderColor = '#ccc';
                if (e.dataTransfer.files[0]) processFile(e.dataTransfer.files[0]);
            });
        }
        
        // Load TensorFlow.js model
        async function loadModel() {
            try {
                document.getElementById('status').textContent = "Loading model (≈30MB)...";
                
                // Verify model exists
                const response = await fetch(MODEL_PATH);
                if (!response.ok) throw new Error("Model files not found");
                
                // Load the model
                model = await tf.loadGraphModel(MODEL_PATH);
                document.getElementById('status').textContent = "Model loaded! Select an image";
                console.log("Model loaded successfully:", model);
            } catch (error) {
                document.getElementById('status').textContent = `Error loading model: ${error.message}`;
                console.error("Model loading failed:", error);
            }
        }
        
        // Process uploaded file
        function processFile(file) {
            if (!file.type.match('image.*')) {
                document.getElementById('status').textContent = "Please select an image file";
                return;
            }
            
            const img = new Image();
            img.onload = () => {
                if (model) {
                    processImage(img).catch(error => {
                        document.getElementById('status').textContent = `Error: ${error.message}`;
                        console.error("Processing error:", error);
                    });
                } else {
                    document.getElementById('status').textContent = "Model not loaded yet";
                }
            };
            img.src = URL.createObjectURL(file);
        }
        
        // Main processing function
        async function processImage(img) {
            document.getElementById('status').textContent = "Processing...";
            
            try {
                // Create square canvas with original image centered
                const { canvas, offsetX, offsetY, width, height } = createPaddedCanvas(img);
                
                // Show padded original
                document.getElementById('original').src = canvas.toDataURL();
                document.getElementById('original').style.display = 'block';
                
                // Convert to tensor and normalize
                const tensor = tf.tidy(() => {
                    return tf.browser.fromPixels(canvas)
                        .toFloat()
                        .div(255)
                        .expandDims();
                });
                
                // Execute model - IMPORTANT: Use the correct input name
                const output = await model.executeAsync(tensor, 'Identity');
                const mask = output.squeeze();
                
                // Create final result
                await applyMask(canvas, mask, offsetX, offsetY, width, height);
                
                // Clean up
                tensor.dispose();
                output.dispose();
                mask.dispose();
                
                document.getElementById('status').textContent = "Done!";
            } catch (error) {
                // Force memory cleanup
                await tf.nextFrame();
                throw error;
            }
        }
        
        // Create properly padded canvas
        function createPaddedCanvas(img) {
            const canvas = document.createElement('canvas');
            canvas.width = TARGET_SIZE;
            canvas.height = TARGET_SIZE;
            const ctx = canvas.getContext('2d');
            
            // Fill with black background
            ctx.fillStyle = 'black';
            ctx.fillRect(0, 0, TARGET_SIZE, TARGET_SIZE);
            
            // Calculate dimensions to maintain aspect ratio
            const ratio = Math.min(
                TARGET_SIZE / img.width, 
                TARGET_SIZE / img.height
            );
            const width = Math.floor(img.width * ratio);
            const height = Math.floor(img.height * ratio);
            const offsetX = (TARGET_SIZE - width) / 2;
            const offsetY = (TARGET_SIZE - height) / 2;
            
            // Draw centered image
            ctx.drawImage(img, offsetX, offsetY, width, height);
            
            return { canvas, offsetX, offsetY, width, height };
        }
        
        // Apply mask to create final result
        async function applyMask(paddedCanvas, mask, offsetX, offsetY, width, height) {
            const resultCanvas = document.getElementById('result');
            resultCanvas.width = width;
            resultCanvas.height = height;
            const resultCtx = resultCanvas.getContext('2d');
            
            // Get mask data
            const maskData = await mask.array();
            const imageData = paddedCanvas.getContext('2d').getImageData(0, 0, TARGET_SIZE, TARGET_SIZE);
            const resultData = resultCtx.createImageData(width, height);
            
            // Process each pixel
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const srcX = Math.floor(offsetX) + x;
                    const srcY = Math.floor(offsetY) + y;
                    const srcIdx = (srcY * TARGET_SIZE + srcX) * 4;
                    const dstIdx = (y * width + x) * 4;
                    
                    // Copy RGB channels
                    resultData.data[dstIdx] = imageData.data[srcIdx];
                    resultData.data[dstIdx+1] = imageData.data[srcIdx+1];
                    resultData.data[dstIdx+2] = imageData.data[srcIdx+2];
                    
                    // Apply mask (threshold at 0.5)
                    resultData.data[dstIdx+3] = maskData[srcY][srcX] > 0.5 ? 255 : 0;
                }
            }
            
            // Apply to result canvas
            resultCtx.putImageData(resultData, 0, 0);
            resultCanvas.style.display = 'block';
            
            // Set download link
            document.getElementById('download').href = resultCanvas.toDataURL('image/png');
            document.getElementById('download').style.display = 'inline-block';
        }
    </script>
</body>
</html>
