<!DOCTYPE html>
<html>
<head>
    <title>Fast Quality Background Remover</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; }
        #upload-container { margin: 20px 0; padding: 30px; border: 2px dashed #ccc; text-align: center; }
        #original, #result { max-width: 100%; max-height: 500px; display: none; margin-top: 20px; border: 1px solid #eee; }
        #download { margin: 20px auto; padding: 10px 20px; background: #4CAF50; color: white; border: none; border-radius: 4px; display: none; }
        #status { margin: 10px 0; min-height: 24px; }
        .container { display: flex; gap: 20px; justify-content: center; }
        .column { flex: 1; text-align: center; }
        button { padding: 10px 20px; background: #4285f4; color: white; border: none; border-radius: 4px; cursor: pointer; }
    </style>
</head>
<body>
    <h1>Fast Quality Background Remover</h1>
    <div id="upload-container">
        <input type="file" id="upload" accept="image/*" style="display: none;">
        <button onclick="document.getElementById('upload').click()">Select Image</button>
        <p>or drag and drop image here</p>
    </div>
    
    <div id="status">Loading model...</div>
    
    <div class="container">
        <div class="column">
            <h3>Original</h3>
            <img id="original">
        </div>
        <div class="column">
            <h3>Result</h3>
            <canvas id="result"></canvas>
        </div>
    </div>
    
    <a id="download" href="#" download="no-bg.png">Download Result</a>

    <script>
        // Configuration
        const MODEL_PATH = 'model/model.json';
        const TARGET_SIZE = 320; // UÂ²-Net expects 320x320
        
        // Global variables
        let model = null;
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            setupDragDrop();
            loadModel();
            
            document.getElementById('upload').addEventListener('change', (e) => {
                if (e.target.files[0]) processFile(e.target.files[0]);
            });
        });
        
        // Setup drag and drop
        function setupDragDrop() {
            const container = document.getElementById('upload-container');
            
            container.addEventListener('dragover', (e) => {
                e.preventDefault();
                container.style.borderColor = '#4285f4';
            });
            
            container.addEventListener('dragleave', () => {
                container.style.borderColor = '#ccc';
            });
            
            container.addEventListener('drop', (e) => {
                e.preventDefault();
                container.style.borderColor = '#ccc';
                if (e.dataTransfer.files[0]) processFile(e.dataTransfer.files[0]);
            });
        }
        
        // Load TensorFlow.js model
        async function loadModel() {
            try {
                document.getElementById('status').textContent = "Loading model...";
                
                // Verify model exists
                const response = await fetch(MODEL_PATH);
                if (!response.ok) throw new Error("Model files not found");
                
                // Load the model
                model = await tf.loadGraphModel(MODEL_PATH);
                document.getElementById('status').textContent = "Ready! Select an image";
            } catch (error) {
                document.getElementById('status').textContent = `Error loading model: ${error.message}`;
                console.error("Model loading failed:", error);
            }
        }
        
        // Process uploaded file
        function processFile(file) {
            if (!file.type.match('image.*')) {
                document.getElementById('status').textContent = "Please select an image file";
                return;
            }
            
            const img = new Image();
            img.onload = async () => {
                if (model) {
                    try {
                        document.getElementById('status').textContent = "Processing...";
                        
                        // Show original
                        document.getElementById('original').src = img.src;
                        document.getElementById('original').style.display = 'block';
                        
                        // Create working canvas at target size
                        const { canvas, scale } = createWorkingCanvas(img);
                        
                        // Process with model
                        const mask = await generateMask(canvas);
                        
                        // Create high quality result
                        await createHighQualityResult(img, mask, scale);
                        
                        document.getElementById('status').textContent = "Done!";
                    } catch (error) {
                        document.getElementById('status').textContent = `Error: ${error.message}`;
                        console.error("Processing error:", error);
                    }
                } else {
                    document.getElementById('status').textContent = "Model not loaded yet";
                }
            };
            img.src = URL.createObjectURL(file);
        }
        
        // Create working canvas at target size while maintaining aspect ratio
        function createWorkingCanvas(img) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            // Calculate dimensions to maintain aspect ratio
            const scale = Math.min(
                TARGET_SIZE / img.width, 
                TARGET_SIZE / img.height
            );
            canvas.width = Math.floor(img.width * scale);
            canvas.height = Math.floor(img.height * scale);
            
            // Draw image
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
            
            return { canvas, scale };
        }
        
        // Generate mask from image
        async function generateMask(canvas) {
            // Create padded input for model (320x320)
            const paddedCanvas = document.createElement('canvas');
            paddedCanvas.width = TARGET_SIZE;
            paddedCanvas.height = TARGET_SIZE;
            const paddedCtx = paddedCanvas.getContext('2d');
            
            // Fill with black and center the image
            paddedCtx.fillStyle = 'black';
            paddedCtx.fillRect(0, 0, TARGET_SIZE, TARGET_SIZE);
            const offsetX = (TARGET_SIZE - canvas.width) / 2;
            const offsetY = (TARGET_SIZE - canvas.height) / 2;
            paddedCtx.drawImage(canvas, offsetX, offsetY);
            
            // Convert to tensor and normalize
            const tensor = tf.tidy(() => {
                return tf.browser.fromPixels(paddedCanvas)
                    .toFloat()
                    .div(255)
                    .expandDims();
            });
            
            // Execute model
            const output = await model.executeAsync(tensor);
            const mask = output.squeeze();
            
            // Clean up
            tensor.dispose();
            output.dispose();
            
            return { mask, offsetX, offsetY };
        }
        
        // Create high quality result from original image
        async function createHighQualityResult(img, { mask, offsetX, offsetY }, scale) {
            const resultCanvas = document.getElementById('result');
            resultCanvas.width = img.width;
            resultCanvas.height = img.height;
            const resultCtx = resultCanvas.getContext('2d');
            
            // Draw original image
            resultCtx.drawImage(img, 0, 0);
            
            // Get mask data
            const maskData = await mask.array();
            const imageData = resultCtx.getImageData(0, 0, img.width, img.height);
            
            // Apply mask to each pixel
            for (let y = 0; y < img.height; y++) {
                for (let x = 0; x < img.width; x++) {
                    // Calculate position in mask
                    const maskX = Math.floor(x * scale) + offsetX;
                    const maskY = Math.floor(y * scale) + offsetY;
                    
                    // Only process if within mask bounds
                    if (maskX >= 0 && maskX < TARGET_SIZE && maskY >= 0 && maskY < TARGET_SIZE) {
                        const maskValue = maskData[maskY][maskX] > 0.5 ? 255 : 0;
                        const idx = (y * img.width + x) * 4 + 3;
                        imageData.data[idx] = maskValue;
                    }
                }
            }
            
            // Apply to result canvas
            resultCtx.putImageData(imageData, 0, 0);
            resultCanvas.style.display = 'block';
            
            // Set download link
            document.getElementById('download').href = resultCanvas.toDataURL('image/png');
            document.getElementById('download').style.display = 'inline-block';
            
            // Clean up
            mask.dispose();
        }
    </script>
</body>
</html>
